{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2aefda5",
      "metadata": {
        "id": "c2aefda5"
      },
      "source": [
        "# SemEval 2026 Task 5\n",
        "\n",
        "This notebook trains a **Transformer** model to predict plausibility scores (1–5) for word senses in narrative contexts.\n",
        "\n",
        "Metrics reported:\n",
        "- Spearman correlation\n",
        "- Accuracy within standard deviation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tYtXCpFRXt1C",
      "metadata": {
        "id": "tYtXCpFRXt1C"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130\n",
        "\n",
        "# %pip install -q transformers datasets accelerate evaluate scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe7d4a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe7d4a8",
        "outputId": "8580040c-c288-4d6e-af87-f901ee84a8fe"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import statistics\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed,\n",
        " )\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    print('Running in Google Colab. Mounting Google Drive...')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_ROOT = Path('/content/drive/My Drive/Colab Notebooks/semeval26-05-scripts')\n",
        "else:\n",
        "    print('Not running in Google Colab.')\n",
        "    PROJECT_ROOT = Path.cwd()\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "TRAIN_JSON = DATA_DIR / 'train.json'\n",
        "DEV_JSON = DATA_DIR / 'dev.json'\n",
        "TEST_JSON = DATA_DIR / 'test.json'\n",
        "\n",
        "assert TEST_JSON.exists(), f'Missing: {TEST_JSON}'\n",
        "assert TRAIN_JSON.exists(), f'Missing: {TRAIN_JSON}'\n",
        "assert DEV_JSON.exists(), f'Missing: {DEV_JSON}'\n",
        "\n",
        "print('Python:', sys.executable)\n",
        "print('Torch:', torch.__version__)\n",
        "print('Torch CUDA build:', torch.version.cuda)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "print('Train file:', TRAIN_JSON)\n",
        "print('Dev file:', DEV_JSON)\n",
        "print('Test file:', TEST_JSON)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac755f71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac755f71",
        "outputId": "97ab7691-a938-40e1-8923-c851e6d9781a"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "drive_path = Path('/content/drive/My Drive/Colab Notebooks/semeval26-05-scripts/data')\n",
        "\n",
        "if drive_path.exists():\n",
        "    print(f\"Contents of {drive_path}:\")\n",
        "    for item in drive_path.iterdir():\n",
        "        print(f\"- {item.name}\")\n",
        "else:\n",
        "    print(f\"Directory not found: {drive_path}. Please ensure your Google Drive is mounted correctly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9abcfb5",
      "metadata": {
        "id": "a9abcfb5"
      },
      "source": [
        "## 2) Data loading\n",
        "Load the JSON files and convert them into flat examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bd57b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3bd57b0",
        "outputId": "e56b8cba-b528-43d3-9ce1-8b967fbd39e3"
      },
      "outputs": [],
      "source": [
        "def load_split(path):\n",
        "    with path.open('r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def iter_sorted_items(raw):\n",
        "    for k in sorted(raw.keys(), key=lambda x: int(x)):\n",
        "        yield k, raw[k]\n",
        "\n",
        "train_raw = load_split(TRAIN_JSON)\n",
        "dev_raw = load_split(DEV_JSON)\n",
        "test_raw = load_split(TEST_JSON)\n",
        "\n",
        "print('Train samples:', len(train_raw))\n",
        "print('Dev samples:', len(dev_raw))\n",
        "print('Test samples:', len(test_raw))\n",
        "print('Example fields:', list(next(iter(train_raw.values())).keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae40e924",
      "metadata": {
        "id": "ae40e924"
      },
      "source": [
        "## 3) Data preprocessing\n",
        "Build the model input text and labels.\n",
        "\n",
        "We fine-tune a Transformer **classifier** to predict an integer score (1–5).\n",
        "To help the model, we format inputs with explicit sections (precontext/sentence/ending/etc.) plus a direct question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511116d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "511116d5",
        "outputId": "0241ac93-40aa-4fea-c035-8f4ad51f0316"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path('/content/drive/My Drive/Colab Notebooks/semeval26-05-scripts')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "TRAIN_JSON = DATA_DIR / 'train.json'\n",
        "DEV_JSON = DATA_DIR / 'dev.json'\n",
        "\n",
        "def load_split(path):\n",
        "    with path.open('r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def iter_sorted_items(raw):\n",
        "    for k in sorted(raw.keys(), key=lambda x: int(x)):\n",
        "        yield k, raw[k]\n",
        "\n",
        "train_raw = load_split(TRAIN_JSON)\n",
        "dev_raw = load_split(DEV_JSON)\n",
        "\n",
        "import re\n",
        "def mark_homonym(text, hom):\n",
        "    hom = (hom or \"\").strip()\n",
        "    if not hom:\n",
        "        return text\n",
        "    pattern = re.compile(rf\"\\b({re.escape(hom)})\\b\", flags=re.IGNORECASE)\n",
        "    return pattern.sub(r\"<t> \\1 </t>\", text, count=1)\n",
        "\n",
        "def build_pair(sample):\n",
        "    pre = str(sample.get('precontext', '')).strip()\n",
        "    sent = str(sample.get('sentence', '')).strip()\n",
        "    end = str(sample.get('ending', '')).strip()\n",
        "\n",
        "    hom = str(sample.get('homonym', '')).strip()\n",
        "    meaning = str(sample.get('judged_meaning', '')).strip()\n",
        "    ex = str(sample.get('example_sentence', '')).strip()\n",
        "\n",
        "    story = \" \".join(x for x in [pre, sent, end] if x)\n",
        "    story = mark_homonym(story, hom)\n",
        "\n",
        "    nons = sample.get(\"nonsensical\", [])\n",
        "    n_rate = sum(bool(x) for x in nons) / max(1, len(nons))\n",
        "    sense = f\"{hom} = {meaning}. Example: {ex}. Nonsense_votes: {n_rate:.2f}\"\n",
        "    return story, sense\n",
        "\n",
        "def choices_to_soft(choices):\n",
        "    counts = np.zeros(5, dtype=np.float32)\n",
        "    for c in choices:\n",
        "        counts[int(c) - 1] += 1.0\n",
        "    probs = counts / counts.sum()\n",
        "    return probs.tolist()\n",
        "\n",
        "def clip_round_to_1_5(x):\n",
        "    return int(np.clip(int(round(float(x))), 1, 5))\n",
        "\n",
        "train_ids, train_a, train_b, train_labels_soft = [], [], [], []\n",
        "for k, s in iter_sorted_items(train_raw):\n",
        "    a, b = build_pair(s)\n",
        "    train_ids.append(k)\n",
        "    train_a.append(a)\n",
        "    train_b.append(b)\n",
        "    train_labels_soft.append(choices_to_soft(list(map(int, s['choices']))))\n",
        "\n",
        "dev_ids, dev_a, dev_b, dev_labels_soft = [], [], [], []\n",
        "dev_avg, dev_choices = [], []\n",
        "for k, s in iter_sorted_items(dev_raw):\n",
        "    a, b = build_pair(s)\n",
        "    dev_ids.append(k)\n",
        "    dev_a.append(a)\n",
        "    dev_b.append(b)\n",
        "    dev_labels_soft.append(choices_to_soft(list(map(int, s['choices']))))\n",
        "    dev_avg.append(float(s['average']))\n",
        "    dev_choices.append(list(map(int, s['choices'])))\n",
        "\n",
        "test_ids, test_a, test_b = [], [], []\n",
        "\n",
        "for k, s in iter_sorted_items(test_raw):\n",
        "    a, b = build_pair(s)\n",
        "    sid = str(s.get(\"sample_id\", k))\n",
        "    test_ids.append(sid)\n",
        "    test_a.append(a)\n",
        "    test_b.append(b)\n",
        "\n",
        "\n",
        "print('Train size:', len(train_ids), 'Dev size:', len(dev_ids))\n",
        "print('Dev rounded distribution:', {i: sum(clip_round_to_1_5(a) == i for a in dev_avg) for i in range(1, 6)})\n",
        "print('\\nSample story (A):\\n', train_a[0][:300])\n",
        "print('\\nSample sense  (B):\\n', train_b[0][:200])\n",
        "print(\"Sample test A:\", test_a[0][:200])\n",
        "print(\"Sample test B:\", test_b[0][:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46e3b27",
      "metadata": {
        "id": "d46e3b27"
      },
      "source": [
        "## 4) Tokenization\n",
        "Tokenize the text with a pretrained Transformer tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309c1720",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593,
          "referenced_widgets": [
            "5b64fcb55a4e4cc099e24215d117f3e8",
            "f7d44c8fbfd347c395f0001365815d5d",
            "c0ca06e585864bf79ceab14f8abf2409",
            "265849a858724d6bb5019e6615eb379f",
            "8917776db0294372976300aead63532e",
            "a2e1c727c65140f7ba43abe4013b4eab",
            "d6bfbcbc49cb4d02a49c2bd865a8939c",
            "e13a6576900e41e5b2b61516883f4d3c",
            "51d7d867564f4eafad9534f58844097e",
            "811e785c2b0a4474ba5c39237cb3fbc8",
            "59e0823719444802a58e8be1f2143082",
            "5af482b4d1dd4ad5822c55d3dfa1224c",
            "7e9e2cf169ce46b8a2b93a2384a929a0",
            "16d6e9e7475b47c0be2badfbad450dd8",
            "a4e1c527a26c4bd08a60cb3a5e8c8f81",
            "aaa5e3ef29da4211b3d7c583cc0e3258",
            "3f0f89c2ebe9402b9ca81d270fd23e4b",
            "6b34b936e8404f0c8f32f2a70b6a7fb9",
            "f470ed97b1ae4aaba0f007bb9c24cf5c",
            "f971badfd9d64704a11fd9dad315a39d",
            "47bfe3f0815e41929da7b214f92f365d",
            "716ac052e9fe4255960c8ae35e86744f",
            "0207adda8f564a7f812fe83aeaf834db",
            "3e90f83be0a944e0b605d1e0d7840c2f",
            "6986b23abe6b4485bd4ff1d053ea1524",
            "4f1f4968dde8453ba817d7d402643206",
            "417bcfb6d537446f88d9a097eaf464c8",
            "f685259256b04a4ab8a196f25a12fe36",
            "fc4c2ad29ce74ab4a82e734aac5a4047",
            "c70df076a69d46108096d3d025ddc9ff",
            "930bc56e6572492f94795e0850d6125e",
            "5f59d803f00747909c7c0de1860ff964",
            "72c01bf90a564e12af66ac13c6f1e803",
            "04c1220dd4b84e8684f4e82a4ef564f4",
            "f4cac856c6b54012af42a8cbf598228d",
            "4107bb2ab4ce4beea4b0b80097ee702a",
            "8109e289350a4f91b180a45781260739",
            "7db9888650954d37a23b9c597f7e80ad",
            "a3ed6644a5534b93bfa1363b2bbfb3c4",
            "652de53e9890467ba6a98967791d16ea",
            "c23cd6bf43f04b6b96d2a3301fc63076",
            "7d8f5ac358f44c068cd6d7dd509d579f",
            "595bfb550e2240f29a90589258108e0b",
            "d67705b4d82847aea8ebb75dc84cb908",
            "e87058a37bb14746863341d8406109dc",
            "8df125c1cc774fb4a01ec44c92d90323",
            "b1960db21ef543a3837ca34135e6a962",
            "e235b8b7ec41417f8843a4c8651677df",
            "28e63d491f9f41a6b513a73e2b158c37",
            "05fe5cf92c5c4c18a73f310290d7c60f",
            "98f19af0b7924a6fb68dc948dfabb984",
            "870bed1c938c44ce907f3c4b62935a41",
            "b811d17cda2a454cb45f51e829f780f5",
            "b46980e97775477cb1ac27ad30cc35ad",
            "0aee5d0c0f554d50b4320b989f2a6648",
            "6d5859482bf7431bb07a24a6cade971a",
            "fd916f3a58c64bb29b30679423a98c91",
            "50058da179be42c88c6586c9954adbf6",
            "0057e7c999f240d78ad23dac5d63cce2",
            "f611f47d0aba47638e64b7eaacad24d2",
            "e786fa1f3fef4a279efd19eb55064d1e",
            "831c235a82d04823bee1e32a3e97e74c",
            "5605daffcaf84a8891b5af6c4825e1c8",
            "91d27b2cacea43289c0aaf0ac7c86814",
            "a3381cfc399c49c6a26854d03ecf27a8",
            "5c9d1f5d4eaf4a90848281ac263e50f6"
          ]
        },
        "id": "309c1720",
        "outputId": "52f1d83f-b306-4f27-a1c7-d4f7e0887147"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding, set_seed\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
        "\n",
        "MAX_LENGTH = 320\n",
        "LEARNING_RATE = 6.605331684042691e-06\n",
        "NUM_EPOCHS = 8\n",
        "WEIGHT_DECAY = 0.038665688189882155\n",
        "WARMUP_RATIO = 0.07954725255425056\n",
        "SEED = 42\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "tokenizer.add_tokens([\"<t>\", \"</t>\"])\n",
        "\n",
        "train_ds = Dataset.from_dict({\n",
        "    'id': train_ids,\n",
        "    'text_a': train_a,\n",
        "    'text_b': train_b,\n",
        "    'labels': train_labels_soft,\n",
        "})\n",
        "dev_ds = Dataset.from_dict({\n",
        "    'id': dev_ids,\n",
        "    'text_a': dev_a,\n",
        "    'text_b': dev_b,\n",
        "    'labels': dev_labels_soft,\n",
        "})\n",
        "\n",
        "test_ds = Dataset.from_dict({\n",
        "    \"id\": test_ids,\n",
        "    \"text_a\": test_a,\n",
        "    \"text_b\": test_b,\n",
        "})\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch['text_a'],\n",
        "        batch['text_b'],\n",
        "        truncation='only_first',\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "train_tok = train_ds.map(tokenize_batch, batched=True, remove_columns=['text_a', 'text_b'])\n",
        "dev_tok = dev_ds.map(tokenize_batch, batched=True, remove_columns=['text_a', 'text_b'])\n",
        "test_tok = test_ds.map(tokenize_batch, batched=True, remove_columns=[\"text_a\", \"text_b\"])\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=tokenizer,\n",
        "    pad_to_multiple_of=8 if USE_CUDA else None,\n",
        ")\n",
        "\n",
        "print(f'Model: {MODEL_NAME} | MAX_LENGTH={MAX_LENGTH} | epochs={NUM_EPOCHS} | lr={LEARNING_RATE}')\n",
        "print(train_tok)\n",
        "print(dev_tok)\n",
        "print(test_tok)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4632587",
      "metadata": {
        "id": "c4632587"
      },
      "source": [
        "## 5) Model + training\n",
        "We fine-tune a pretrained model as a **5-class classifier** (labels 1–5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4b22f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829,
          "referenced_widgets": [
            "1835b0448bf0450bbca4c13d54cf235d",
            "becf2439d75448e196844689b2558c29",
            "d684f79eaa10499aa5effd8365348241",
            "fc1380797d5945f5ba4c23fdb52ee4f6",
            "15de70e7e0274c0bb0ddcb5745ac1bdf",
            "4e193ccd532742f98db157f63d997e0a",
            "3d6847e635344f7dad528bcee5a9df35",
            "1e746624c80b450c9f310ab5e6d564c9",
            "5478ea13a4be472bbebef05be75a90b7",
            "a071b64461174311964012c7e7e9b638",
            "7930ed41198f4f458a45e3ec5e38c068",
            "d7670b5dd74241a6b87bacdc6e6c9c2a",
            "77c781f6484f4690b9096c8692ce287b",
            "1215b2578ad9434b98fb67fc4bd52fe8",
            "0963bdea8435430aa8dc9a20115c77dd",
            "c718b5b657234c87a5b402cca44fa9d4",
            "5af1cf69cc3e4f65bfb923c5c1bf1b8e",
            "86301979cc854c04acdd48b63fe902dc",
            "1ba4416bb2e043bcb2ab9fbfb7c7cdb7",
            "82914b5504e343b59e6414087e8682ee",
            "b4b357ed23824187b3ba79510e186940",
            "892697dd296d442d87c8a21866f0af71"
          ]
        },
        "id": "ed4b22f7",
        "outputId": "1309ce0f-9bde-4681-84ee-b6fd4a399fec"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"CUDA:\", use_cuda)\n",
        "if use_cuda:\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# if use_cuda:\n",
        "#    torch.cuda.empty_cache()\n",
        "\n",
        "def is_within_standard_deviation(prediction, labels):\n",
        "    avg = sum(labels) / len(labels)\n",
        "    stdev = statistics.stdev(labels)\n",
        "    if (avg - stdev) < prediction < (avg + stdev):\n",
        "        return True\n",
        "    if abs(avg - prediction) < 1:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, _ = eval_pred\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
        "\n",
        "    pred_argmax = (probs.argmax(axis=-1) + 1).astype(int)\n",
        "\n",
        "    weights = np.arange(1, 6, dtype=np.float32)\n",
        "    ev = (probs * weights).sum(axis=1)\n",
        "    pred_ev = np.clip(np.digitize(ev, [1.5, 2.5, 3.5, 4.5]) + 1, 1, 5)\n",
        "\n",
        "    counts = np.bincount(pred_ev, minlength=6)[1:6]\n",
        "    print(\"Counts ratings 1..5 (EV):\", counts)\n",
        "\n",
        "    spearman_corr_ev, _ = spearmanr(pred_ev.tolist(), np.asarray(dev_avg, dtype=float))\n",
        "    acc_within_sd_ev = sum(\n",
        "        is_within_standard_deviation(int(p), choices)\n",
        "        for p, choices in zip(pred_ev.tolist(), dev_choices)\n",
        "    ) / len(dev_choices)\n",
        "\n",
        "    spearman_corr_am, _ = spearmanr(pred_argmax.tolist(), np.asarray(dev_avg, dtype=float))\n",
        "    acc_within_sd_am = sum(\n",
        "        is_within_standard_deviation(int(p), choices)\n",
        "        for p, choices in zip(pred_argmax.tolist(), dev_choices)\n",
        "    ) / len(dev_choices)\n",
        "\n",
        "    return {\n",
        "        \"spearman_ev\": float(spearman_corr_ev) if spearman_corr_ev == spearman_corr_ev else 0.0,\n",
        "        \"acc_within_sd_ev\": float(acc_within_sd_ev),\n",
        "        \"spearman_argmax\": float(spearman_corr_am) if spearman_corr_am == spearman_corr_am else 0.0,\n",
        "        \"acc_within_sd_argmax\": float(acc_within_sd_am),\n",
        "        \"acc_within_sd\": float(max(acc_within_sd_ev, acc_within_sd_am)),\n",
        "    }\n",
        "\n",
        "def compute_loss_func(outputs, labels, num_items_in_batch=None):\n",
        "    logits = outputs.logits\n",
        "    soft = labels.to(logits.device)\n",
        "    hard = soft.argmax(dim=-1)\n",
        "\n",
        "    loss_hard = F.cross_entropy(logits, hard)\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    loss_soft = -(soft * log_probs).sum(dim=-1).mean()\n",
        "    p = 0.10490799853094769\n",
        "    return p * loss_soft + (1 - p) * loss_hard\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "PER_DEVICE_TRAIN_BS = 8 if use_cuda else 2\n",
        "GRAD_ACCUM = 1 if use_cuda else 4\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(PROJECT_ROOT / \"transformer_runs_best\"),\n",
        "    overwrite_output_dir=True,\n",
        "    do_eval=True,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=PER_DEVICE_TRAIN_BS,\n",
        "    per_device_eval_batch_size=8 if use_cuda else 4,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    fp16=use_cuda,\n",
        "    optim=\"adamw_torch\",\n",
        "    dataloader_pin_memory=use_cuda,\n",
        "    dataloader_num_workers=0,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"acc_within_sd\",\n",
        "    greater_is_better=True,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=200,\n",
        "    report_to=[],\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=dev_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_loss_func=compute_loss_func,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(f\"Training {MODEL_NAME} | bs={PER_DEVICE_TRAIN_BS} | grad_accum={GRAD_ACCUM} | epochs={NUM_EPOCHS}\")\n",
        "trainer.train()\n",
        "\n",
        "eval_result = trainer.evaluate()\n",
        "print(\"\\n=== Final Evaluation (best checkpoint) ===\")\n",
        "print(eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed76b62",
      "metadata": {},
      "source": [
        "# Parameter tuning with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41113764",
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, set_seed\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"CUDA:\", use_cuda)\n",
        "if use_cuda:\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "def tokenize_with_length(max_len):\n",
        "    def tok(batch):\n",
        "        return tokenizer(\n",
        "            batch[\"text_a\"],\n",
        "            batch[\"text_b\"],\n",
        "            truncation=\"only_first\",\n",
        "            max_length=max_len,\n",
        "        )\n",
        "    tr = train_ds.map(tok, batched=True, remove_columns=[\"text_a\", \"text_b\"])\n",
        "    dv = dev_ds.map(tok, batched=True, remove_columns=[\"text_a\", \"text_b\"])\n",
        "    return tr, dv\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    trial_seed = SEED + trial.number\n",
        "    set_seed(trial_seed)\n",
        "\n",
        "    lr = trial.suggest_float(\"learning_rate\", 3e-6, 3e-5, log=True)\n",
        "    wd = trial.suggest_float(\"weight_decay\", 0.0, 0.05)\n",
        "    warmup = trial.suggest_float(\"warmup_ratio\", 0.03, 0.20)\n",
        "    epochs = trial.suggest_int(\"num_train_epochs\", 3, 8)\n",
        "\n",
        "    max_len = trial.suggest_categorical(\"max_length\", [256, 320, 384, 512])\n",
        "    bs = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 24, 32])\n",
        "    grad_accum = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2])\n",
        "\n",
        "    soft_w = trial.suggest_float(\"soft_weight\", 0.05, 0.25)\n",
        "\n",
        "    train_tok, dev_tok = tokenize_with_length(max_len)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    def trial_compute_loss(outputs, labels, num_items_in_batch=None):\n",
        "        logits = outputs.logits\n",
        "        soft = labels.to(logits.device)\n",
        "\n",
        "        weights = torch.arange(1, 6, device=logits.device, dtype=soft.dtype)\n",
        "        hard = torch.clamp(torch.round((soft * weights).sum(dim=-1)), 1, 5).long() - 1\n",
        "\n",
        "        loss_hard = F.cross_entropy(logits, hard)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        loss_soft = -(soft * log_probs).sum(dim=-1).mean()\n",
        "\n",
        "        return soft_w * loss_soft + (1.0 - soft_w) * loss_hard\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=str(PROJECT_ROOT / f\"optuna_trial_{trial.number:03d}\"),\n",
        "        overwrite_output_dir=True,\n",
        "        do_eval=True,\n",
        "\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=bs,\n",
        "        per_device_eval_batch_size=min(bs, 32),\n",
        "        gradient_accumulation_steps=grad_accum,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=wd,\n",
        "        warmup_ratio=warmup,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "\n",
        "        bf16=use_cuda,\n",
        "        fp16=False,\n",
        "\n",
        "        optim=\"adamw_torch\",\n",
        "        dataloader_pin_memory=use_cuda,\n",
        "        dataloader_num_workers=2,\n",
        "\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"acc_within_sd\",\n",
        "        greater_is_better=True,\n",
        "\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=200,\n",
        "        report_to=[],\n",
        "        seed=trial_seed,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_tok,\n",
        "        eval_dataset=dev_tok,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_loss_func=trial_compute_loss,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    score = float(metrics[\"eval_acc_within_sd\"])\n",
        "\n",
        "    trial.report(score, step=epochs)\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"\\n=== BEST ===\")\n",
        "print(\"best value:\", study.best_value)\n",
        "print(\"best params:\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ce5768",
      "metadata": {
        "id": "b7ce5768"
      },
      "source": [
        "## 6) Generate predictions.jsonl\n",
        "Export test predictions as required by the SemEval format: one JSON per line with `id` and integer `prediction` in [1..5]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38db78c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "38db78c9",
        "outputId": "ed021af5-8645-4623-e026-4d61834a698d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "pred_out = trainer.predict(test_tok)\n",
        "logits = pred_out.predictions\n",
        "probs = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
        "\n",
        "weights = np.arange(1, 6, dtype=np.float32)\n",
        "ev = (probs * weights).sum(axis=1)\n",
        "pred_int = np.clip(np.digitize(ev, [1.5, 2.5, 3.5, 4.5]) + 1, 1, 5).astype(int).tolist()\n",
        "\n",
        "out_path = PROJECT_ROOT / \"predictions_test.jsonl\"\n",
        "id = 0\n",
        "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for sid, p in zip(test_ids, pred_int):\n",
        "        f.write(json.dumps({\"id\": str(id), \"prediction\": int(p)}) + \"\\n\")\n",
        "        id += 1\n",
        "\n",
        "print(\"Wrote:\", out_path)\n",
        "print(\"Sample preds:\", list(zip(test_ids[:10], pred_int[:10])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf496c6",
      "metadata": {
        "id": "bbf496c6"
      },
      "source": [
        "## 7) (Optional) Run official scorer\n",
        "This validates formatting and reports official metrics on dev."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0f9c4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0f9c4a",
        "outputId": "d67ff753-37f8-4d03-dcd7-682e61ad5909"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "scoring_script = PROJECT_ROOT / 'semeval26-05-scripts' / 'scoring.py'\n",
        "gold = PROJECT_ROOT / 'semeval26-05-scripts' / 'input' / 'ref' / 'solution.jsonl'\n",
        "preds = PROJECT_ROOT / 'semeval26-05-scripts' / 'input' / 'res' / 'predictions.jsonl'\n",
        "scores_out = PROJECT_ROOT / 'semeval26-05-scripts' / 'output' / 'scores.json'\n",
        "scores_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cmd = [\n",
        "    str(Path(sys.executable)),\n",
        "    str(scoring_script),\n",
        "    str(gold),\n",
        "    str(preds),\n",
        "    str(scores_out),\n",
        "]\n",
        "\n",
        "print('Running:', ' '.join(cmd))\n",
        "result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "print(result.stdout)\n",
        "print(result.stderr)\n",
        "print('Scores JSON:', scores_out)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
